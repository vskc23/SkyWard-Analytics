{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CXVzTQ0-MP3",
        "outputId": "3626b56e-9bd2-446a-b81e-e2fcfdf825cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tFJACCnZ-XFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "def combine_csv_from_zip_by_year(folder_path, year):\n",
        "    all_dataframes = []\n",
        "    zip_files = [f for f in os.listdir(folder_path) if f.endswith('.zip') and str(year) in f]\n",
        "\n",
        "    print(f\"Number of zip files for the year {year}: {len(zip_files)}\")\n",
        "\n",
        "    for zip_filename in zip_files:\n",
        "        zip_file_path = os.path.join(folder_path, zip_filename)\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "            for file_name in z.namelist():\n",
        "                if file_name.endswith('.csv'):\n",
        "                    with z.open(file_name) as file:\n",
        "                        df = pd.read_csv(file)\n",
        "                        all_dataframes.append(df)\n",
        "\n",
        "    if all_dataframes:\n",
        "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "        return combined_df\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Transport_5_years'\n",
        "\n",
        "year_to_combine = 2023\n",
        "combined_csv = combine_csv_from_zip_by_year(folder_path, year_to_combine)\n",
        "\n",
        "if not combined_csv.empty:\n",
        "    output_directory = '/content/drive/MyDrive/Transport_5_years'\n",
        "    output_file = f'combined_transport_{year_to_combine}.csv'\n",
        "    output_path = os.path.join(output_directory, output_file)\n",
        "\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    combined_csv.to_csv(output_path, index=False)\n",
        "    print(f\"The combined CSV file for the year {year_to_combine} has been saved to:\", output_path)\n",
        "else:\n",
        "    print(f\"No CSV files found for the year {year_to_combine}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgco8gxFGWFe",
        "outputId": "60626d3f-0abe-43a3-9895-23cf07a1a779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of zip files for the year 2023: 12\n",
            "The combined CSV file for the year 2023 has been saved to: /content/drive/MyDrive/Transport_5_years/combined_transport_2023.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transport_df = pd.read_csv('/content/drive/MyDrive/data/Transport_5_years/combined_transport_2019.csv')\n",
        "bird_strike_df = pd.read_excel('/content/drive/MyDrive/data/bird_5_years/2019.xlsx')"
      ],
      "metadata": {
        "id": "x2SQ9ZhZXpVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55d51e5-6c2c-4395-f9f5-42f63af13ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-07b2fea11ae9>:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  transport_df = pd.read_csv('/content/drive/MyDrive/data/Transport_5_years/combined_transport_2019.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing Airport codes\n",
        "\n",
        "data = \"\"\n",
        "with open(\"/content/drive/MyDrive/AirCode.txt\", \"r\") as f:\n",
        "  data = f.read()\n",
        "  f.close()\n",
        "\n",
        "data = data.split(\"\\n\")\n",
        "airport_codes = {}\n",
        "for d in data:\n",
        "  temp = d.split(\":\")\n",
        "  airport_codes[temp[0]] = temp[1]\n",
        "\n",
        "airlines = pd.read_csv('/content/drive/MyDrive/airlines.csv')\n",
        "airports = pd.read_csv('/content/drive/MyDrive/airports.csv')\n",
        "airports = airports.rename(columns={'IATA_CODE':'ORIGIN'})\n",
        "airlines = airlines.rename(columns={'IATA_CODE':'OP_UNIQUE_CARRIER'})"
      ],
      "metadata": {
        "id": "moUKtDDeW-sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bird_strike_df = bird_strike_df.replace({\"AIRPORT_ID\": airport_codes})\n",
        "transport_df = transport_df.merge(airports, on='ORIGIN')\n",
        "transport_df = transport_df.merge(airlines, on='OP_UNIQUE_CARRIER')"
      ],
      "metadata": {
        "id": "tuUs1ajcXqGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert date formats to match\n",
        "transport_df['FL_DATE'] = pd.to_datetime(transport_df['FL_DATE'])\n",
        "bird_strike_df['INCIDENT_DATE '] = pd.to_datetime(bird_strike_df['INCIDENT_DATE '])\n",
        "\n",
        "# Standardize airport codes\n",
        "transport_df['FL_NUMBER'] = transport_df['FL_NUMBER'].astype(str).str.strip().str.upper()\n",
        "bird_strike_df['FLT'] = bird_strike_df['FLT'].str.strip().str.upper()\n",
        "\n",
        "# Standardize airport codes\n",
        "transport_df['ORIGIN'] = transport_df['ORIGIN'].str.strip().str.upper()\n",
        "transport_df['DEST'] = transport_df['DEST'].str.strip().str.upper()\n",
        "bird_strike_df['AIRPORT_ID'] = bird_strike_df['AIRPORT_ID'].str.strip().str.upper()\n",
        "\n",
        "# Merge the datasets using Airport Code and Date as the merge keys\n",
        "merged_df_source = pd.merge(transport_df, bird_strike_df,\n",
        "                     left_on=[\"ORIGIN\", \"FL_DATE\", \"OP_CARRIER_FL_NUM\"],\n",
        "                     right_on=[\"AIRPORT_ID\", \"INCIDENT_DATE \", \"FLT\"],\n",
        "                     how=\"inner\")\n",
        "\n",
        "merged_df_dest = pd.merge(transport_df, bird_strike_df,\n",
        "                     left_on=[\"DEST\", \"FL_DATE\", \"OP_CARRIER_FL_NUM\"],\n",
        "                     right_on=[\"AIRPORT_ID\", \"INCIDENT_DATE \", \"FLT\"],\n",
        "                     how=\"inner\")\n",
        "merged_df = pd.concat([merged_df_source, merged_df_dest], ignore_index=True)\n",
        "if merged_df.empty:\n",
        "    print(\"No matching records found.\")\n",
        "else:\n",
        "    # Post-merge processing\n",
        "    # Handle missing values, create new features, etc.\n",
        "    merged_df.fillna(0, inplace=True)\n",
        "\n",
        "    # Save the merged csv\n",
        "    merged_df.to_csv(\"/content/drive/MyDrive/SD/merged_2019.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUqZ5ComXH_f",
        "outputId": "4cd3e894-7281-4fa9-f39d-52e7b15973c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-747fb20dc696>:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  transport_df['FL_DATE'] = pd.to_datetime(transport_df['FL_DATE'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_2023_df = pd.read_csv('/content/drive/MyDrive/SD/merged_2019.csv')\n",
        "print(len(merged_2023_df))"
      ],
      "metadata": {
        "id": "ehsrkxNzY9bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70b45b9-156b-4a8d-c823-3ffb4f0cec71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-f2f5a46c2153>:1: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  merged_2023_df = pd.read_csv('/content/drive/MyDrive/SD/merged_2019.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging all CSVs\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/SD/merged_2019.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2020.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2021.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2022.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2023.csv'\n",
        "]\n",
        "\n",
        "dataframes = [pd.read_csv(file) for file in file_paths]\n",
        "\n",
        "combined_csv = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "output_path = '/content/drive/MyDrive/SD/combined_all_SD.csv'\n",
        "\n",
        "combined_csv.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"The combined CSV file has been saved to: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEFEnxvadHg3",
        "outputId": "4d987d2d-8c8c-4dc9-c74f-61b8ddfc9e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-5566e053f338>:11: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dataframes = [pd.read_csv(file) for file in file_paths]\n",
            "<ipython-input-41-5566e053f338>:11: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dataframes = [pd.read_csv(file) for file in file_paths]\n",
            "<ipython-input-41-5566e053f338>:11: DtypeWarning: Columns (60,134) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dataframes = [pd.read_csv(file) for file in file_paths]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The combined CSV file has been saved to: /content/drive/MyDrive/SD/combined_all_SD.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.read_csv('/content/drive/MyDrive/SD/combined_all_SD.csv')\n",
        "print(len(combined_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-SZI-IgdmGX",
        "outputId": "84d17783-ee47-43ad-fd1a-c185d05b51a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-020709d41a34>:1: DtypeWarning: Columns (60,134) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  combined_df = pd.read_csv('/content/drive/MyDrive/SD/combined_all_SD.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(combined_df))"
      ],
      "metadata": {
        "id": "K0kkBJw1drtc",
        "outputId": "5b2939c9-cf3c-4895-cb9a-ea9c9509134b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbINQnpfTPNG",
        "outputId": "37df9dcc-2274-42d6-b636-a11da5aa9b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['YEAR', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'FL_DATE',\n",
            "       'OP_UNIQUE_CARRIER', 'OP_CARRIER_AIRLINE_ID', 'TAIL_NUM',\n",
            "       'OP_CARRIER_FL_NUM', 'ORIGIN_AIRPORT_ID',\n",
            "       ...\n",
            "       'NR_INJURIES', 'NR_FATALITIES', 'COMMENTS', 'REPORTER_NAME',\n",
            "       'REPORTER_TITLE', 'SOURCE', 'PERSON', 'LUPDATE', 'IMAGE', 'TRANSFER'],\n",
            "      dtype='object', length=149)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYCb7PcjTF_i",
        "outputId": "c3291168-0c92-4c87-b907-019a3917ff7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of        YEAR  MONTH  DAY_OF_MONTH  DAY_OF_WEEK     FL_DATE OP_UNIQUE_CARRIER  \\\n",
            "0      2019     10             2            3  2019-10-02                AA   \n",
            "1      2019     10             2            3  2019-10-02                DL   \n",
            "2      2019     10             5            6  2019-10-05                AA   \n",
            "3      2019     10             5            6  2019-10-05                DL   \n",
            "4      2019     10             7            1  2019-10-07                AA   \n",
            "...     ...    ...           ...          ...         ...               ...   \n",
            "10982  2023      1             7            6  2023-01-07                HA   \n",
            "10983  2023      1             7            6  2023-01-07                HA   \n",
            "10984  2023      7             5            3  2023-07-05                HA   \n",
            "10985  2023      4             5            3  2023-04-05                HA   \n",
            "10986  2023      9            21            4  2023-09-21                HA   \n",
            "\n",
            "       OP_CARRIER_AIRLINE_ID TAIL_NUM  OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID  \\\n",
            "0                      19805   N986NN               1409              10397   \n",
            "1                      19790   N918DH               1409              10397   \n",
            "2                      19805   N810NN               2344              10397   \n",
            "3                      19790   N866DN               2344              10397   \n",
            "4                      19805   N836AW                823              10599   \n",
            "...                      ...      ...                ...                ...   \n",
            "10982                  19690   N216HA                 24              13830   \n",
            "10983                  19690   N218HA                 58              13830   \n",
            "10984                  19690   N384HA                 34              13830   \n",
            "10985                  19690   N475HA                341              12402   \n",
            "10986                  19690   N485HA                121              12402   \n",
            "\n",
            "       ...  NR_INJURIES  NR_FATALITIES  \\\n",
            "0      ...          0.0            0.0   \n",
            "1      ...          0.0            0.0   \n",
            "2      ...          0.0            0.0   \n",
            "3      ...          0.0            0.0   \n",
            "4      ...          0.0            0.0   \n",
            "...    ...          ...            ...   \n",
            "10982  ...          0.0            0.0   \n",
            "10983  ...          0.0            0.0   \n",
            "10984  ...          0.0            0.0   \n",
            "10985  ...          0.0            0.0   \n",
            "10986  ...          0.0            0.0   \n",
            "\n",
            "                                                COMMENTS REPORTER_NAME  \\\n",
            "0                                                      0      REDACTED   \n",
            "1                                                      0      REDACTED   \n",
            "2                                                      0      REDACTED   \n",
            "3                                                      0      REDACTED   \n",
            "4                                                      0      REDACTED   \n",
            "...                                                  ...           ...   \n",
            "10982  *** Strike Report: XXXX-XX-XX-XXXXXX-RX( Repor...      REDACTED   \n",
            "10983  *** Strike Report: XXXX-XX-XX-XXXXXX-RX( Repor...      REDACTED   \n",
            "10984  *** Strike Report: XXXX-XX-XX-XXXXXX-RX( Repor...      REDACTED   \n",
            "10985  *** Strike Report: XXXX-XX-XX-XXXXXX-RX( Repor...      REDACTED   \n",
            "10986  *** Strike Report: XXXX-XX-XX-XXXXXX-RX( Repor...      REDACTED   \n",
            "\n",
            "      REPORTER_TITLE             SOURCE              PERSON     LUPDATE  \\\n",
            "0           REDACTED       Daily Report               Tower  2020-04-29   \n",
            "1           REDACTED       Daily Report               Tower  2020-04-29   \n",
            "2           REDACTED  FAA Form 5200-7-E               Pilot  2020-02-21   \n",
            "3           REDACTED  FAA Form 5200-7-E               Pilot  2020-02-21   \n",
            "4           REDACTED    FAA Form 5200-7               Pilot  2020-04-28   \n",
            "...              ...                ...                 ...         ...   \n",
            "10982       REDACTED           Multiple  Airport Operations  2023-05-31   \n",
            "10983       REDACTED           Multiple  Airport Operations  2023-05-31   \n",
            "10984       REDACTED           Multiple  Airport Operations  2023-09-11   \n",
            "10985       REDACTED           Multiple               Tower  2023-06-15   \n",
            "10986       REDACTED           Multiple               Tower  2024-03-29   \n",
            "\n",
            "       IMAGE TRANSFER  \n",
            "0      False    False  \n",
            "1      False    False  \n",
            "2      False    False  \n",
            "3      False    False  \n",
            "4      False    False  \n",
            "...      ...      ...  \n",
            "10982  False    False  \n",
            "10983  False    False  \n",
            "10984   True    False  \n",
            "10985  False    False  \n",
            "10986  False    False  \n",
            "\n",
            "[10987 rows x 149 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_paths = [\n",
        "    '/content/drive/MyDrive/SD/merged_2019.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2020.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2021.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2022.csv',\n",
        "    '/content/drive/MyDrive/SD/merged_2023.csv'\n",
        "]\n",
        "\n",
        "dataframes = [pd.read_csv(file) for file in file_paths]\n",
        "\n",
        "combined_csv = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "output_path = '/content/drive/MyDrive/SD/combined_all_SD.csv'\n",
        "\n",
        "combined_csv.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"The combined CSV file has been saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "yUfmDlbmbGNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/data/Transport_5_years/Sep-2019.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "def combine_csv_from_zip_by_year(folder_path, month):\n",
        "    all_dataframes = []\n",
        "    zip_files = [f for f in os.listdir(folder_path) if f.endswith('.zip') and str(month) in f]\n",
        "    print(zip_files)\n",
        "    for zip_filename in zip_files:\n",
        "        zip_file_path = os.path.join(folder_path, zip_filename)\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "            for file_name in z.namelist():\n",
        "                if file_name.endswith('.csv'):\n",
        "                    with z.open(file_name) as file:\n",
        "                        df = pd.read_csv(file)\n",
        "                        all_dataframes.append(df)\n",
        "\n",
        "    if all_dataframes:\n",
        "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
        "        return combined_df\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/data/Transport_5_years'\n",
        "\n",
        "month = 'Sep'\n",
        "combined_csv = combine_csv_from_zip_by_year(folder_path, month)\n",
        "\n",
        "if not combined_csv.empty:\n",
        "    output_directory = '/content/drive/MyDrive/data/Transport_5_years'\n",
        "    output_file = f'combined_transport_{month}.csv'\n",
        "    output_path = os.path.join(output_directory, output_file)\n",
        "\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    combined_csv.to_csv(output_path, index=False)\n",
        "    print(f\"The combined CSV file for the year {month} has been saved to:\", output_path)\n",
        "else:\n",
        "    print(f\"No CSV files found for the year {month}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPDw_Ldxbcuw",
        "outputId": "c791fc23-097b-49e7-b27f-8624dcf717f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sep-2019.zip', 'Sep-2021.zip', 'Sep-2022.zip', 'Sep-2023.zip', 'Sep-2020.zip']\n",
            "The combined CSV file for the year Sep has been saved to: /content/drive/MyDrive/data/Transport_5_years/combined_transport_Sep.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Epk3YLuub4XE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}